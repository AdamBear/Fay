
此文件是Fay框架项目二次开发约定，供程序员和ai 编程工具阅读。

一、Fay框架的作用
1、实现简单的数字人交互
这种实现方式最为简单，在Fay框架基础上，你只需要考虑用什么皮肤和llm,以及在什么地方接收用户的信息，然后又把信息输出到那里。
a、接收的信息
接收的信息可以是文本信息（flask_server.py中实现），也可以是语音信息(fay_booter.py中实现)。可以从本机接收，也可以从网络接收。
b、输出的信息
输出的信息可以是文本信息（flask_server.py中实现），也可以是语音信息(fay_booter.py中实现)。可以向本机输出，也可以向网络输出。
c、皮肤
Fay框架通过数字人接口来驱动皮肤，若用户想驱动自己的皮肤，可以对接咱们定义的数字人接口（wsa_server.py,10002端口）。
d、llm
在llm目录下我们已经为大量的llm实现了对接，只需要在system.conf配置chat_module即可，若用户需要补充，可以参考nlp_gpt.py的实现，并在fay_core.py中引入。

2、为数字人提供“眼睛”
我们将智能硬件、摄像头、手机等外部终端设备视为眼睛。终端设备把识别的数据和文本交互信息一起发给Fay（flask_server.py中api_send_v1_chat_completions()方法的observation），Fay根据数据进行处理及回应。更复杂的情况可以参照flask_server.py中的打招呼或唤醒补充其他意图接口。

3、为数字人提供“手”
通过把chat_module配置为agent,并参照llm/agent/tools/下的工具的实现补充更丰富的工具，可以让数字人的手为我们工作。

4、调度三方系统
构建以数字人为中心的高度智能系统，只需要“让眼看见，让手触达”。

二、Fay框架的使用原则
1、首先明确用户使用Fay框架的目的。
2、然后评估Fay的功能是否已经满足用户的需求。
3、最后再考虑怎么样做最少的修改来达到用户的目的。
4、只实现用户最直接需求，不要给过多的建议。
5、请尽量遵照原工程的编码规范。
6、如果你不知道用户目的，请先问清楚。
7、遵循 PEP 8 编码规范，注重提高代码可读性和一致性​。
8、请说中文，不要说英文。

三、Fay框架的源码结构
├── main.py              # 主程序入口
├── fay_booter.py        # 启动器，管理录音设备和系统初始化
├── config.json          # 配置文件
├── system.conf          # 系统配置
├── requirements.txt     # 依赖包列表
├── fay.db              # 主数据库
├── timer.db            # 定时任务数据库
├── user_profiles.db    # 用户配置数据库
├── qa.csv              # QA问答数据
├── verifier.json       # 验证配置
│
├── core/               # 数字人核心目录
│   ├── fay_core.py     # 核心控制器，处理交互逻辑和TTS
│   ├── recorder.py     # 录音模块，音频采集和VAD检测
│   ├── wsa_server.py   # WebSocket服务，处理实时通信
│   ├── qa_service.py   # QA服务，处理问答逻辑
│   ├── interact.py     # 交互基类，定义交互接口
│   ├── content_db.py   # 内容数据库管理
│   ├── member_db.py    # 用户数据库管理
│   ├── authorize_tb.py # 认证表管理
│   └── socket_bridge_service.py # Socket桥接服务
│
├── asr/                # 语音识别模块
│   ├── ali_nls.py      # 阿里云语音识别
│   ├── funasr.py       # FunASR语音识别
│   └── funasr/         # FunASR服务器相关文件
│
├── tts/               # 语音合成模块
│   ├── ms_tts_sdk.py   # 微软TTS实现
│   ├── ali_tss.py      # 阿里云TTS实现
│   ├── gptsovits.py    # GPT-SoVITS实现
│   ├── gptsovits_v3.py # GPT-SoVITS V3实现
│   ├── volcano_tts.py  # 火山TTS实现
│   └── tts_voice.py    # 语音类型和风格定义
│
├── llm/               # 大语言模型模块
│   ├── agent/          # AI代理目录
│   ├── nlp_gpt.py      # ChatGPT实现
│   ├── nlp_rasa.py     # Rasa实现
│   ├── nlp_lingju.py   # 灵聚AI实现
│   ├── nlp_xingchen.py # 星尘AI实现
│   ├── nlp_coze.py     # Coze AI实现
│   ├── nlp_qingliu.py  # 清流AI实现
│   ├── nlp_accompany.py # 陪伴AI实现
│   ├── nlp_ChatGLM3.py # ChatGLM3实现
│   ├── nlp_VisualGLM.py # VisualGLM实现
│   ├── nlp_ollama_api.py # Ollama API实现
│   ├── nlp_privategpt.py # Private GPT实现
│   ├── nlp_rwkv.py     # RWKV实现
│   └── VllmGPT.py      # vLLM GPT实现
│
├── ai_module/          # AI功能模块
│   ├── baidu_emotion.py # 百度情感分析
│   └── nlp_cemotion.py  # 自定义情感分析
│
├── gui/               # 图形界面模块
│   ├── flask_server.py  # Flask Web服务器
│   ├── window.py       # 窗口程序实现
│   ├── robot/          # 机器人资源目录
│   ├── static/         # 静态资源目录
│   └── templates/      # 页面模板目录
│
├── utils/             # 工具模块
│   ├── config_util.py  # 配置管理工具
│   ├── util.py        # 通用工具函数
│   ├── stream_util.py # 流处理工具
│   └── openai_api/    # OpenAI API工具
│
├── scheduler/         # 调度管理
│   └── thread_manager.py # 线程管理器
│
├── cache_data/        # 缓存数据目录
│   └── input.wav      # 临时音频文件
│
├── samples/          # 音频样本目录
│   └── sample-*.wav   # TTS生成的音频文件
│
├── logs/             # 日志目录
│   ├── asr_result.txt  # 语音识别结果日志
│   └── answer_result.txt # 回答结果日志
│
├── docker/           # Docker相关
│   └── Dockerfile    # Docker配置文件
│
├── shell/            # Shell脚本
│   └── *.sh         # 各种脚本文件
│
└── test/            # 测试目录
    └── *            # 测试文件和资源